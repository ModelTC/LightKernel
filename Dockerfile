ARG CUDA_VERSION=12.6.1
FROM nvidia/cuda:${CUDA_VERSION}-cudnn-devel-ubuntu22.04
ARG PYTHON_VERSION=3.10
ARG MAMBA_VERSION=24.7.1-0
ARG TARGETPLATFORM

ENV PATH=/opt/conda/bin:$PATH \
    CONDA_PREFIX=/opt/conda

# Install system dependencies
RUN chmod 777 -R /tmp && apt-get update && DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \
    ca-certificates \
    libssl-dev \
    curl \
    g++ \
    make \
    git \
    cmake \
    ninja-build \
    build-essential \
    ccache && \
    rm -rf /var/lib/apt/lists/*

# Install Mambaforge
RUN case ${TARGETPLATFORM} in \
    "linux/arm64")  MAMBA_ARCH=aarch64  ;; \
    *)              MAMBA_ARCH=x86_64   ;; \
    esac && \
    curl -fsSL -o ~/mambaforge.sh -v "https://github.com/conda-forge/miniforge/releases/download/${MAMBA_VERSION}/Mambaforge-${MAMBA_VERSION}-Linux-${MAMBA_ARCH}.sh" && \
    bash ~/mambaforge.sh -b -p /opt/conda && \
    rm ~/mambaforge.sh

# Install Python
RUN case ${TARGETPLATFORM} in \
    "linux/arm64")  exit 1 ;; \
    *)              /opt/conda/bin/conda update -y conda &&  \
    /opt/conda/bin/conda install -y "python=${PYTHON_VERSION}" ;; \
    esac && \
    /opt/conda/bin/conda clean -ya

# Set working directory
WORKDIR /workspace

# Install PyTorch with CUDA support
RUN pip install torch==2.7.1

# Install build dependencies + æ„å»ºåŠ é€Ÿå·¥å…·
RUN pip install --upgrade pip setuptools wheel build scikit-build-core[pyproject] pybind11 ninja psutil

# ğŸš€ è®¾ç½®ccacheç¼–è¯‘ç¼“å­˜åŠ é€Ÿ
ENV CCACHE_DIR=/tmp/ccache \
    CCACHE_MAXSIZE=2G \
    CCACHE_COMPRESS=true \
    CC="ccache gcc" \
    CXX="ccache g++"
RUN ccache --set-config=max_size=2G

# Copy source code to container
COPY . .

# ğŸ”§ è®¾ç½® PyTorch è·¯å¾„ï¼Œè®© CMake èƒ½æ‰¾åˆ° Torch é…ç½®
# è·å– PyTorch å®‰è£…è·¯å¾„å¹¶è®¾ç½® CMAKE_PREFIX_PATH
RUN python -c "import torch; print(f'PyTorch installed at: {torch.__path__[0]}')" && \
    TORCH_PATH=$(python -c "import torch; print(torch.utils.cmake_prefix_path)") && \
    echo "Torch CMAKE path: $TORCH_PATH"

# Set environment variables for building
ENV FLASH_ATTENTION_FORCE_BUILD=TRUE \
    FLASH_ATTENTION_DISABLE_BACKWARD=TRUE \
    CUDA_HOME=/usr/local/cuda \
    CUDA_ROOT=/usr/local/cuda \
    CCACHE_DISABLE=0

# ğŸ¯ å…³é”®ä¿®å¤ï¼šè®¾ç½® CMAKE_PREFIX_PATH è®© CMake æ‰¾åˆ° PyTorch
RUN TORCH_CMAKE_PATH=$(python -c "import torch; print(torch.utils.cmake_prefix_path)") && \
    echo "export CMAKE_PREFIX_PATH=$TORCH_CMAKE_PATH:\$CMAKE_PREFIX_PATH" >> ~/.bashrc && \
    echo "CMAKE_PREFIX_PATH=$TORCH_CMAKE_PATH" >> /etc/environment

# ğŸš€ GitHub Actionsä¼˜åŒ–ï¼šæ™ºèƒ½è®¾ç½®å¹¶è¡Œåº¦ï¼ˆé’ˆå¯¹2æ ¸7GBé™åˆ¶ï¼‰
RUN python -c "\
import os, psutil; \
cpu_cores = min(2, os.cpu_count()); \
available_memory_gb = min(7, psutil.virtual_memory().available / (1024**3)); \
memory_jobs = max(1, int(available_memory_gb / 3)); \
optimal_jobs = min(cpu_cores, memory_jobs, 2); \
nvcc_threads = optimal_jobs; \
print(f'ğŸ¯ CIä¼˜åŒ–: MAX_JOBS={optimal_jobs}, NVCC_THREADS={nvcc_threads}'); \
print(f'ğŸ’¾ ä¼°ç®—èµ„æº: {available_memory_gb:.1f}GB, {cpu_cores}æ ¸'); \
f = open('/etc/environment', 'a'); \
f.write(f'MAX_JOBS={optimal_jobs}\n'); \
f.write(f'NVCC_THREADS={nvcc_threads}\n'); \
f.close()"

# Create output directory
RUN mkdir -p /out



# Build lightllm-kernel package (main project)  
RUN echo "ğŸ”§ Building lightllm-kernel package..." && \
    echo "ğŸ“‹ Verifying PyTorch installation..." && \
    python -c "import torch; print(f'PyTorch version: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CMake prefix path: {torch.utils.cmake_prefix_path}')" && \
    eval $(cat /etc/environment | xargs -I {} echo export {}) && \
    TORCH_CMAKE_PATH=$(python -c "import torch; print(torch.utils.cmake_prefix_path)") && \
    echo "ğŸ”§ Setting CMAKE_PREFIX_PATH to: $TORCH_CMAKE_PATH" && \
    echo "ğŸš€ Using optimized settings: MAX_JOBS=$MAX_JOBS, NVCC_THREADS=$NVCC_THREADS" && \
    CMAKE_PREFIX_PATH="$TORCH_CMAKE_PATH:$CMAKE_PREFIX_PATH" python -m build --wheel --outdir /out/ && \
    echo "âœ… lightllm-kernel build completed"

# Build flash_attn_3 package (hopper) - æºç ä¼˜åŒ–æ„å»º
RUN echo "ğŸ”§ Building flash_attn_3 from source with optimizations..." && \
    cd flash-attention/hopper && \
    eval $(cat /etc/environment | xargs -I {} echo export {}) && \
    echo "ğŸš€ Optimized settings: MAX_JOBS=$MAX_JOBS, NVCC_THREADS=$NVCC_THREADS" && \
    echo "â° GitHub Actions: Building within 6h time limit..." && \
    MAX_JOBS=$MAX_JOBS NVCC_THREADS=$NVCC_THREADS FLASH_ATTN_CUDA_ARCHS=90 python setup.py bdist_wheel && \
    cp dist/*.whl /out/ && \
    echo "âœ… flash_attn_3 optimized source build completed"

# æ˜¾ç¤ºç¼–è¯‘ç¼“å­˜ç»Ÿè®¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
RUN ccache --show-stats 2>/dev/null || echo "ğŸ’¾ ccache stats not available"

# Verify all wheels are built (æºç æ„å»ºéªŒè¯)
RUN echo "ğŸ“¦ Final wheel packages:" && \
    ls -la /out/ && \
    WHEEL_COUNT=$(ls -1 /out/*.whl | wc -l) && \
    echo "ğŸ¯ Total wheels built: $WHEEL_COUNT" && \
    if [ "$WHEEL_COUNT" -ne 2 ]; then \
        echo "âŒ ERROR: Expected 2 wheels (lightllm-kernel + flash_attn_3), found $WHEEL_COUNT" && \
        echo "ğŸ“‹ Debug info:" && ls -la /out/ && \
        exit 1; \
    else \
        echo "ğŸ‰ SUCCESS: All wheels built from optimized source compilation!"; \
    fi && \
    echo "ğŸ•’ Optimized build completed within GitHub Actions time limit!"